<div dir="rtl">

# סעיף א'
---

קובץ הקלט logs.txt מכיל מיליוני שורות, כאשר כל שורה כוללת קוד שגיאה.  
המטרה היא לזהות את N קודי השגיאה השכיחים ביותר.

## הפעלת הקוד:
הקוד הראשי נמצא בקובץ Section_A/sectionA.py.  
בתוך הקובץ יש לבחור את סוג הקובץ (Excel או טקסט), וכן לקבוע את הערך של N - מספר קודי השגיאה השכיחים שרוצים להחזיר.  
הקובץ המקורי סופק בפורמט Excel ולכן הומר ל-TXT כנדרש, אך יש תמיכה בשני הסוגים.


```bash
python Section_A/sectionA.py

# להרצה על קובץ טקסט רגיל יש לבחור את השורות האלו בקובץ
split_text_log_file("Section_A/logs.txt")
print(get_top_n_errors("Section_A/chunks_txt", N))

# להרצה על קובץ אקסל יש לבחור את השורות האלו בקובץ
split_excel_log_file("Section_A/logs.txt.xlsx")
print(get_top_n_errors("Section_A/chunks_excel", N))

```
יש להחליף את N במספר קודי השגיאה הרצויים.  
## שאלה 5  - ניתוח זמן ריצה:
מספר השורות בקובץ - m.    
מספר קודי השגיאה השונים - k.    
מספר הקודים השכיחים שרוצים להחזיר - N.  

### שלב 1 - פיצול הקובץ: 
**זמן** - מעבר על הקובץ פעם אחת - O(m).  
**מקום** - אנחנו לא שומרים איזשהו מבנה נתונים, לכן - O(1).  

### שלב 2 - ספירת הקודים בכל הקבצים:
**זמן** - מעבר על הקבצים הקטנים ועדכון במילון, כאשר סך השורות זה כמו בקובץ הגדול - O(m).  
**מקום** - שומרים מילון עם מופע עבור כל קוד שגיאה - O(k).  

### שלב 3 - מציאת N קודי השגיאה השכיחים ביותר:
**זמן** - שליפת N הקודים השכיחים בעזרת Counter.most_common - עפ"י הדוקומנטציה של פייתון הוא משתמש בערימה, כלומר יוצרים ערימה בגודל של N ועוברים על כל הקודים ומכניסים לערימה רק אם גדול מאחד הערכים שם, כלומר לעבור על כל הקודים  - O(k), כמו כן הכנסה לערימה  - O(logN) - בסה"כ זמן הריצה - O(klogN).  
[קישור לדוקומנטציה של Counter.most_common](https://github.com/python/cpython/blob/a8e814db96ebfeb1f58bc471edffde2176c0ae05/Lib/collections/__init__.py#L571)  
**מקום** - מחזיקים את N הקודים - O(N).    
  
### **זמן ריצה כולל** - O(m) + O(klogN).  
### **סיבוכיות מקום** - O(k).  
  
</div>
