<div dir="rtl">
 
# סעיף ב'
---
## שאלה 1 - סעיף א':
הבדיקות שבוצעו על הנתונים:   
-בדיקת כפילויות (ללא הסרה).  
-רשומה עם תאריך חסר/לא תקין הוסרה.  
-רשומה עם ערך חסר ב-value הוסרה.  
## שאלה 1 - סעיף ב':
### הפעלת הקוד

יש להריץ את הקובץ הבא:

```bash
python Section_B/sectionB_1.py
```
עבור הרצה של קובץ csv יש לשים בקובץ את השורה:  
compute_hourly_averages("Section_B/time_series.csv", "Section_B/hourly_averages_no_split.csv")   
עבור הרצה של קובץ parquet יש לשים בקובץ את השורה:    
compute_hourly_averages("Section_B/time_series.parquet", "Section_B/hourly_averages_no_split_parquet.csv")   

**הפלט:**  
עבור קובץ CSV:  
Section_B/hourly_averages_no_split.csv  
עבור קובץ Parquet:  
Section_B/hourly_averages_no_split_parquet.csv

הקוד תומך גם בקובץ CSV וגם בקובץ Parquet.
הפורמט מזוהה אוטומטית לפי סיומת הקובץ (csv / parquet).
## שאלה 2 - עיבוד קובץ גדול באמצעות פיצול לפי ימים:
### הפעלת הקוד
להרצת התהליך כולו על קובץ CSV או קובץ Parquet:

```bash
python Section_B/sectionB_2.py
```
עבור הרצה של קובץ csv יש לשים בקובץ את השורה הזו:  
generate_hourly_averages_from_file("Section_B/time_series.csv")

עבור הרצה של קובץ parquet, יש לשים בקובץ את השורה הזו:  
generate_hourly_averages_from_file("Section_B/time_series.parquet", daily_parts_dir='Section_B/daily_parts_parquet', daily_avgs_dir='Section_B/daily_avgs_parquet', output_file='Section_B/final_hourly_averages_split_parquet.csv')

לאחר ההרצה יווצרו תיקיות חדשות בהתאם לסוג הקלט:

עבור קובץ CSV:  
Section_B/daily_parts/ - קבצי מקור מחולקים לפי תאריך  
Section_B/daily_avgs/ - קבצי ממוצע שעתי לפי יום  

קובץ התוצאה:  
Section_B/final_hourly_averages_split.csv
  
עבור קובץ Parquet:  
Section_B/daily_parts_parquet/ - קבצי מקור מחולקים לפי תאריך  
Section_B/daily_avgs_parquet/ - קבצי ממוצע שעתי לפי יום  
  
קובץ התוצאה:  
Section_B/final_hourly_averages_split_parquet.csv

**שימוש ב-Threads:**  בשלב חישוב הממוצעים השעתיים - מתבצע שימוש ב־4 פתילים במקביל.  
היתרון בכך:    
-מקצר משמעותית את זמן העיבוד.  
-מאפשר חישוב עצמאי לכל קובץ.  

**הערה:** עקב כך שקובץ ה-parquet לא הגיע בפורמט הדרוש, אזי בוצעה המרה של קובץ ה-csv לפורמט הדרוש.
## שאלה 3 - הגעת הנתונים בזרימה:  
כאשר הנתונים לא מתקבלים מקובץ שלם, אלא מגיעים שורה־שורה במהלך הזמן, יש לטפל בכל רשומה מיד כשהיא מתקבלת ולעדכן את החישוב בהתאם. כדי לחשב את הממוצע עבור כל שעה בזמן אמת, נשתמש במילון, בו המפתח מייצג שעה מסוימת, ולכל שעה כזו נשמרים שני ערכים: הסכום של כל הערכים שהתקבלו באותה שעה(sum), וכמה ערכים כאלה התקבלו עד עכשיו(count). ברגע שמגיעה רשומה חדשה, מתבצע חישוב לאיזו שעה היא שייכת (על ידי עיגול כלפי מטה לשעה הקרובה), ואז הסכום והכמות של אותה שעה מתעדכנים. כאשר נרצה לדעת מה הממוצע של שעה מסוימת – נחלק את הסכום במספר הערכים(average = sum/count). בנוסף, בכל פעם שמגיעה רשומה ששייכת לשעה חדשה, נדע שהשעה הקודמת הסתיימה, ונוכל לשמור את הממוצע שחישבנו עד כה לקובץ, ולאחר מכן למחוק את הנתונים של אותה שעה מהזיכרון. בצורה הזו אפשר להמשיך לעבד את המידע בלי לשמור את כל ההיסטוריה, מה שחוסך מקום בזיכרון ומאפשר עיבוד של כמויות גדולות של נתונים בזמן אמת.  
בפתרון הנוכחי נשמרים לכל שעה רק סכום הערכים ומספרם. כאשר יש צורך לשמור את כל הרשומות עצמן לצורכי בקרה, ניתן לאגור את הרשומות של כל שעה במבנה זמני, ולבצע כתיבה מרוכזת לקובץ עם סיום השעה.

## שאלה 4 - יתרונות השימוש בפורמט Parquet:  
פורמט Parquet הוא פורמט בינארי, המיועד לאחסון יעיל של כמויות גדולות של נתונים. זהו פורמט טורי, שבו הנתונים נשמרים לפי עמודות ולא לפי שורות, מה שמאפשר גישה סלקטיבית לעמודות מסוימות בלבד ולחסכון משמעותי בזמן קריאה. בנוסף, פורמט זה תומך בדחיסה פנימית חכמה ובשמירה מדויקת של טיפוסי הנתונים (כגון מספרים, תאריכים וערכים חסרים), מה שמפחית את נפח הקובץ ומשפר את אמינות העיבוד. תכונות אלו הופכות את Parquet לבחירה מיטבית עבור סדרות זמן ונתונים גדולים, במיוחד כאשר נדרש לבצע חישובים סטטיסטיים, סינון לפי טווחי זמן, או עבודה עם מערכות עיבוד מתקדמות.  
בהשוואה לפורמט CSV, שמבוסס על טקסט ושורות ודורש טעינה מלאה והמרות טיפוסים ידניות, Parquet מציע פתרון יעיל, מדויק וגמיש יותר — הן בעבודה המקומית והן במערכות בקנה מידה גדול.

</div>